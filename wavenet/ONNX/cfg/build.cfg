[Common]
mode = build
use_aqt = True

[Parser]
model_type = onnx
input_data_format = NCHW
model_name = wavenet
detection_postprocess = 
model_domain = speech_recognition
input_model = input/wavenet_with_ctc.onnx
output_dir = ./IR/ft32/ 
output = CTCGreedyDecoder

[AutoQuantizationTool]
output_nodes = 
quantize_method = SYMMETRIC
ops_per_channel = DepthwiseConv
reverse_rgb = False
quantize_batch_size = 1
input_scale = 1.0
input_mean = 0.0
label_id_offset = 0
preprocess_mode = mfcc
dataset_name = aishell
quant_param = .
quant_precision = int8
ts_max_file = input/wavenet_max.npy 
ts_min_file = input/wavenet_min.npy 

[GBuilder]
outputs = aipu_onnx_wavenetZ2_1104.bin
target = Z2_1104

